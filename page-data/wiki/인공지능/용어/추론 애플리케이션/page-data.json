{"componentChunkName":"component---src-components-gatsby-templates-wiki-tsx","path":"/wiki/인공지능/용어/추론 애플리케이션/","result":{"data":{"file":{"fields":{"gitLogLatestHash":"8aceeeb70224655d0f757b78649a59d8947789ef","gitLogLatestDate":"2024-02-29T15:25:21Z"},"childMarkdownRemark":{"headings":[{"value":"추론 애플리케이션"}],"fields":{"slug":"/인공지능/용어/추론 애플리케이션/","relatedDocs":[{"slug":"javascript","similarity":0.4309893833},{"slug":"web","similarity":0.511523942},{"slug":"2016-08-27-gdg-webtech-workshop-nnn","similarity":0.5471115677},{"slug":"crontab","similarity":0.2376693063},{"slug":"gradle","similarity":0.3522735315},{"slug":"idea-methodology","similarity":0.4407212521},{"slug":"2016-11-16-google-campus-two-things-you-must-keep-in-google-play","similarity":0.5214006636},{"slug":"spring-framework","similarity":0.3632700694},{"slug":"aws","similarity":0.4095502751},{"slug":"git","similarity":0.3615649275},{"slug":"algorithm-practice","similarity":0.325663385},{"slug":"docker","similarity":0.418875596},{"slug":"scp","similarity":0.1839513484},{"slug":"mac-os","similarity":0.4112074629},{"slug":"testing","similarity":0.423635103},{"slug":"machine-learning","similarity":0.5537277166},{"slug":"devops","similarity":0.3741482991},{"slug":"python","similarity":0.372619613},{"slug":"object-oriented-programming","similarity":0.4491253831},{"slug":"linux","similarity":0.2374272437},{"slug":"sfml","similarity":0.3037105556},{"slug":"windows","similarity":0.4652740825},{"slug":"markdown","similarity":0.3299001075},{"slug":"cat-logic","similarity":0.3852356489},{"slug":"vuejs","similarity":0.2780554669},{"slug":"shell","similarity":0.4060708034},{"slug":"html","similarity":0.3045923548},{"slug":"vimenter-2023","similarity":0.4165864859},{"slug":"data-analysis","similarity":0.4347747734},{"slug":"hardware","similarity":0.4356131052},{"slug":"programming-convention","similarity":0.2964027583},{"slug":"webgl","similarity":0.4293245947},{"slug":"sentry","similarity":0.2395255119},{"slug":"valve","similarity":0.3071341039},{"slug":"security","similarity":0.3275732576},{"slug":"reactjs","similarity":0.3839582325},{"slug":"airflow","similarity":0.326091802},{"slug":"computer-graphics","similarity":0.3298629088},{"slug":"elasticsearch","similarity":0.415995685},{"slug":"unicode","similarity":0.2911776985},{"slug":"logging","similarity":0.296509922},{"slug":"tools","similarity":0.4448009327},{"slug":"programming-paradigm","similarity":0.4764372524},{"slug":"system-failures","similarity":0.3185993678},{"slug":"amazon-redshift","similarity":0.2317299694},{"slug":"inspiration","similarity":0.413714847},{"slug":"gatsbyjs","similarity":0.4233880329},{"slug":"design-pattern","similarity":0.4497073402},{"slug":"game","similarity":0.4349456339},{"slug":"kubernetes","similarity":0.3435034306},{"slug":"llm-tools","similarity":0.5957404247},{"slug":"nodejs","similarity":0.5442875509},{"slug":"continuous-integration-and-deployment","similarity":0.2539199909},{"slug":"rust","similarity":0.4383535743},{"slug":"book","similarity":0.3590388392},{"slug":"jetbrains","similarity":0.4176556089},{"slug":"quotation","similarity":0.282061932},{"slug":"postgresql","similarity":0.2611260222},{"slug":"jira","similarity":0.2505858544},{"slug":"swagger","similarity":0.1795818415},{"slug":"architecture","similarity":0.3850870035},{"slug":"unity3d","similarity":0.4008290426},{"slug":"jargon","similarity":0.3894121271},{"slug":"language-server-protocol","similarity":0.3433920081},{"slug":"clean-code","similarity":0.4107392512},{"slug":"java","similarity":0.4270950184},{"slug":"windows-subsystem-for-linux","similarity":0.4070293048},{"slug":"test-driven-development","similarity":0.2656807956},{"slug":"philosophy","similarity":0.4558509411},{"slug":"github","similarity":0.3841226499},{"slug":"network","similarity":0.3171885362},{"slug":"kotlin","similarity":0.3772479526},{"slug":"c-sharp","similarity":0.3542914191},{"slug":"angularjs","similarity":0.3609795043},{"slug":"vim","similarity":0.3117117907},{"slug":"ionic-framework","similarity":0.2528451899},{"slug":"physics","similarity":0.4245761122},{"slug":"html-canvas","similarity":0.3278313323},{"slug":"reverse-engineering","similarity":0.3269923444},{"slug":"space","similarity":0.3649999652},{"slug":"css","similarity":0.3426251331},{"slug":"code-review","similarity":0.4134844221},{"slug":"software-development","similarity":0.4408641214},{"slug":"database","similarity":0.4720053973},{"slug":"reactive-extensions","similarity":0.2411818884},{"slug":"redis","similarity":0.2126300481},{"slug":"mail","similarity":0.2285196454},{"slug":"experience-review","similarity":0.3227251046},{"slug":"google-analytics","similarity":0.3533045908},{"slug":"data-structure","similarity":0.2984201721},{"slug":"vimwiki","similarity":0.3579014662},{"slug":"embeddings","similarity":0.5523423212},{"slug":"추론 애플리케이션","similarity":1}]},"tableOfContents":"<ul>\n<li><a href=\"#%EC%B6%94%EB%A1%A0-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98\">추론 애플리케이션</a></li>\n</ul>","html":"<h1 id=\"추론-애플리케이션\" style=\"position:relative;\"><a href=\"#%EC%B6%94%EB%A1%A0-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98\" aria-label=\"추론 애플리케이션 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>추론 애플리케이션</h1>\n<p>\"추론하다(inference)\"의 의미는 뭘까?</p>\n<p>LLM 관련 글을 읽다보면 모델 추론이라는 표현을 종종 본다.<br>\n의미를 아직 잘 모르겠지만 몇몇 아티클을 읽어보고 추정하는 내용을 정리해본다.</p>\n<p>참고한 아티클은 다음과 같다.</p>\n<ol>\n<li><a href=\"https://news.hada.io/topic?id=11847\">Rust+WASM으로 이기종 Edge에서 빠르고 포터블한 Llama2 추론 실행하기</a></li>\n<li><a href=\"https://news.hada.io/topic?id=8682\">llama.cpp - 페이스북의 LLaMA 모델을 순수 C/C++로 추론하기</a></li>\n<li><a href=\"https://news.hada.io/topic?id=10379\">LLaMa.cpp가 어떻게 가능할까?</a></li>\n</ol>\n<blockquote>\n<p>Python 종속성은 엄청남. Python 또는 PyTorch용 Docker 이미지는 일반적으로 몇 GB 또는 수십 GB에 달하며, 이는 엣지 서버나 디바이스에서 AI 추론을 수행할 때 특히 문제가 됨</p>\n</blockquote>\n<blockquote>\n<p>초경량: 추론 애플리케이션은 모든 종속성을 포함하여 2MB에 불과. 이는 일반적인 PyTorch 컨테이너 크기의 1%도 되지 않음</p>\n</blockquote>\n<blockquote>\n<p>LLaMa 추론 코드를 순수 C++로 재작성한 LLaMA.cpp 덕분에 Pixel5, M2 맥북프로, Raspberry Pi 등 다양한 하드웨어에서 실행 가능</p>\n</blockquote>\n<p>아마도 모델을 사용하는 것을 추론이라고 하는 것 같다.\nPyTorch나 Tensorflow 같은 프레임워크를 사용하여 모델을 불러와서 사용할 수 있다.\n하지만 이러한 프레임워크는 학습을 위한 라이브러리를 제공하거나, 다양한 모델에 대한 기능을 제공하기 때문에 너무 무겁다.\n그래서 전용 \"추론 애플리케이션\"은 가벼운 환경에서 동작케 하는 것이 목적인 것으로 보인다.</p>\n<blockquote>\n<p>맥북에서 LLaMA 모델을 4-bit 양자화하여 실행하는 것을 목표</p>\n</blockquote>\n<p>llama.cpp는 고성능 서버 컴퓨팅이 아닌 맥북과 같은 워크스테이션에서도 실행하는 것이 목적이다.\n첫 번째 아티클은 WASM으로 브라우저에서도 모델 추론을 수행할 수 있도록 하는 것이 목적이다.\n모두 가벼운 컴퓨팅 환경에서 실행 가능케 한다.</p>\n<hr>\n<p><a href=\"https://news.hada.io/topic?id=11980\">https://news.hada.io/topic?id=11980</a></p>\n<blockquote>\n<p>AI가 더욱 주류가 되면서, 우리는 추론(inference) 작업에서 발생하는 부하가 훨씬 더 컴퓨팅 집약적이 될 것으로 기대합니다. 1억 명의 GPT-4 사용자를 서비스하는 데 드는 비용은 모델을 훈련하는 데 소요된 비용의 4배가 될 수 있습니다.</p>\n</blockquote>\n<p>추론을 통해 사용자에게 서비스한다. 그 비용이 학습에 소요되는 비용보다 커진다.</p>\n<hr>\n<p><a href=\"https://www.aitimes.com/news/articleView.html?idxno=155470\">LLM 추론 속도 300배까지 향상...'패스트 피드 포워드' 아키텍처 공개</a></p>\n<blockquote>\n<p>... (중략)\n연구진은 이 기술을 검증하기 위해 트랜스포머 기반의 구글 '버트(BERT)'의 피드 포워드 레이어를 FFF로 대체한 ‘패스트 보트(Fast BERT)’ 모델을 개발했다.</p>\n</blockquote>\n<p>언어 모델의 구조를 잘 모르겠지만, 기존 모델을 크게 변경하지 않고서도 적용이 가능한 모양이다.</p>\n<blockquote>\n<p>특히 연구진은 FFF 네트워크를 LLM에 통합하면 엄청난 가속 가능성이 있다고 주장했다. 예를 들어 'GPT-3'에서 각 트랜스포머의 피드 포워드 네트워크는 4만9152개의 뉴런으로 구성되지만, 15층 깊이의 FFF 네트워크로 대체할 경우 총 6만5536개의 뉴런을 포함하지만 실제 추론에는 GPT-3 뉴런의 약 0.03%에 해당하는 16개만 사용한다.</p>\n</blockquote>\n<p>추론에 사용하는 뉴런의 수를 줄여서 속도를 높였다고 한다.</p>\n<blockquote>\n<p>단일 'A6000' GPU에서 단 하루 동안 훈련한 패스트 버트 모델은 버트 모델 성능의 최소 96%를 유지했으며, 가장 뛰어난 실험 결과에서는 피드 포워드 레이어의 뉴런을 고작 0.3%만 사용하면서 기존 버트 모델과 동일한 성능을 보였다.</p>\n</blockquote>\n<p>단, 성능 저하가 있다고 한다. 그래도 속도 향상이 큰 것에 비해 성능 저하는 매우 적은 편이다.</p>"}},"site":{"siteMetadata":{"gitHubRepositoryUrl":""}}},"pageContext":{"id":"7eabc90b-dde7-5843-89a3-9d002b56f736"}},"staticQueryHashes":[],"slicesMap":{}}